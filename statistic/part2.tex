\documentclass{article}
\usepackage{amsmath}
\usepackage[margin=0.8in]{geometry}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{hyperref} % \url \href

\newcommand{\pfrac}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\rms}{\text{rms}}
% \newcommand{\braket}[1]{\langle #1 \rangle}
% \renewcommand{\H}{\mathcal{H}}

\begin{document}

\title{Kinetic theory}
\author{Wenhao}
\date{\today}
\maketitle

\section{Kinetic theory of ideal gas}
We describe here the problem of motion of molecules in a gas, 
ignoring its rotational and vibration degrees of freedom, with 
energy: 
\begin{equation}
    E_k = \frac{1}{2}mv^2 = \frac{1}{2}m(v_x^2 + v_y^2 + v_z^2)
\end{equation}
we consider some assumption: 1) the molecules do not interact 
with each other most of the time (only through collision) and 2) the collision is 
not frequent. Through the collision, molecules exchange energy with each other,
but every thing remain in equilibrium. We also assume the motion before and 
after the collision is independent, thus their kinetic energies are 
independent variables. With the above assumption, we can consider 
each molecules as an independent system connected to the heat reservior at 
temperature $T$, where heat reservior is "all other molecules in the gas"
\footnote{Blundell, p48} and energy is exchanged with collisions
\footnote{This point
is not stated very clear in the book, but collision is the only way a gas molecule
can interact with other molecules. The motion of the molecule after the collision is
independent of their motion before the collision, therefore, the motion after the 
collision is entirely determined by the heat bath.}.

\subsection*{Velocity distribution}
The velocity distribution $g(\mathbf{v})$ is defined to the fraction of molecules with 
velocity $\mathbf{v}$ 
($\mathbf{v}$ is the vector velocity while $v$ is the absulote value). 
\begin{align}
    g(\mathbf{v}) &\propto e^{-mv^2/2k_BT} dv_xdv_ydv_z \\
    &\propto e^{-m(v_x^2 + v_y^2 + v_z^2)/2k_BT} dv_xdv_ydv_z \\
    &= g(v_x)g(v_y)g(v_z) \label{g_product}
\end{align} 
we find the normalization factor for $g(v_x)$:
\begin{gather}
    \int_{-\infty}^{\infty} e^{-mv_x^2/2k_BT} dv_x = \sqrt{\frac{2\pi k_BT}{m}} \\
    g(v_x) = \sqrt{\frac{m}{2\pi k_BT}} e^{-mv_x^2/2k_BT}
\end{gather}
with $g(v_i)$ normalized to 1, $g(v)$ from Eq.\ref{g_product} is then also normalized to 1.
we can calculate the following values:
\begin{align}
    \langle v_x \rangle &= \int_{-\infty}^{\infty} v_x g(v_x) dv_x = 0 \notag \\
    \langle v_x^2 \rangle &= \int_{-\infty}^{\infty} v_x^2 g(v_x) dv_x = \frac{k_BT}{m} \notag 
\end{align}

To find the distribution with respect to speed $v$ instead of velocity $\mathbf{v}$, we 
consider the volume in velocity phase space corresponding to velocity $v$:
\begin{equation}
    dV = 4\pi v^2 dv
\end{equation}
which correspond to a thin spherical shell at radius $v$. The speed distribution function is then:
\begin{equation}
    f(v) dv \propto v^2 dv e^{-mv^2/2k_BT}
\end{equation}
normalize $\int_0^{\infty}f(v)dv = 1$, we find the distribution function:
\begin{equation}
    f(v) = \frac{4}{\sqrt{\pi}}\left(\frac{m}{2k_BT}\right)^{3/2} v^2 e^{-mv^2/2k_BT}
\end{equation}
which is known as the \textbf{Maxwell-Boltzmann distribution}. 
We can find the following expectation values:
\begin{align}
    \langle v \rangle &= \int_{0}^{\infty} v f(v) dv = \sqrt{\frac{8k_BT}{\pi m}} \notag \\
    \langle v^2 \rangle &= \int_{0}^{\infty} v^2 g(v) dv_x = \frac{3k_BT}{m} \notag  \\
    v_{rms} &= \sqrt{\langle v^2 \rangle} = \sqrt{\frac{3k_BT}{m}}
\end{align}
where $v_{rms}$ is the "root mean square" value. 
The mean kinetic energy of a gas molecule is then:
\begin{equation}
    \langle E_k \rangle = \frac{1}{2}m \langle v^2 \rangle = \frac{3}{2}k_BT
\end{equation}

\subsection*{Pressure}
Since all molecules are equally likely to travel in any direction, the fraction of these 
whose velocity lie in solid angle $d\Omega$ is therefore $d\Omega/4\pi$. We consider the 
molecules traveling at angle between $\theta$ and $\theta + d\theta$ with some specific direction ($z$),
the solid angle is given by:
\begin{equation}
    d\Omega = 2\pi \sin\theta d\theta
\end{equation}
So the fraction of molecules having speed between $v$ and $v_dv$ and angel between $\theta$ 
and $\theta + d\theta$ with direction $z$ is then:
\begin{equation}
    f(v) dv \frac{2\pi \sin\theta d\theta}{4\pi} = \frac{1}{2} f(v) dv \sin\theta d\theta 
\end{equation}

In a time interval $dt$, 
a molecules with speed $v$ travelling at an angle $\theta$ to the normal of the wall
will hit the container wall if it is $vdt\cos \theta$ away from the wall. 
the number of such molecules (speed $v$ at an angle $\theta$) 
hitting the wall of area $A$ is thus 
\begin{equation}
    A vdt\cos \theta n \cdot \frac{1}{2} f(v) dv \sin\theta d\theta 
\end{equation}
where the first part gives the total number of molecules in the volume $A vdt\cos \theta$ and 
the second part is the fraction of the molecule in the velocity and angle range.

Pressure of a gas on its container can be calculated by $dP = F dt$ where $dP$ is the momentum 
change of the particle reflecting from the wall: $dP = 2 mv \cos\theta$ (prependicular to wall). 
Pressure is defined to be $p = F/A$, so that 
We integrate over all possible velocity and angle $\theta$ to obtain the expression of $p$:
\begin{align}
    p &= \int_0^{\infty} dv \int_0^{\pi/2} d\theta  ( 2 mv \cos\theta ) 
    \left( v \cos \theta n \frac{1}{2} f(v) \sin\theta \right) \\
    &= \frac{1}{3} n m \langle v^2 \rangle
\end{align}
using the relationship $n = N/V$ and $\langle v^2 \rangle = 3k_BT / m$, we 
can obtain the ideal gas law:
\begin{equation}
    pV = N k_B T
\end{equation}

\subsection*{Partial pressure}
If we have a mixture of gases in equilibrium, the total pressure will be the 
sum of pressures of each component:
\begin{gather}
    n = \sum_i n_i \\
    p = \left( \sum_i n_i \right) k_B T = \sum_i p_i
\end{gather}
where $n_i = N_i / V$

\subsection*{Effusion}
Effusion is the process in which gas escape from a small hole\footnote{Blundell, p64}. we define 
the flux $\Phi$ as the number of molecules going through unit area per unit time,
therefore, $\Phi$ has the unit of $m^{-2}s^{-1}$. we use the above result of particles 
hitting the wall to find flux:
\begin{align}
    \Phi &= \int_0^{\infty} dv \int_0^{\pi/2} d\theta 
            \left( v \cos \theta n \frac{1}{2} f(v) \sin\theta \right) \label{flux} \\
        &= \frac{1}{4} n \langle v \rangle
\end{align}
with the result:
\begin{align}
    n &= p / k_B T \notag \\
    \langle v \rangle &= \sqrt{\frac{8k_BT}{\pi m}} \notag \\
    \Phi &= \frac{p}{\sqrt{2\pi m k_BT}}
\end{align}

Now, consider a we have a small hole (small enough that the gas escaping does not 
change the equilibrium distribution of gas near the hole), the number of molecules
escaping through the hole is given as:
\begin{equation}
    \Phi A = \frac{pA}{\sqrt{2\pi m k_BT}}
\end{equation}
which is linear to pressure, inversely proportion to $T$ and $m$. 

It should be noted that the speed distribution of the gas through the hole is no longer the 
Maxwell-Boltzmann distribution, since the amount of gas that effuse through the 
hole depend on velocity $v$ (in Eq.\ref{flux}), therefore the speed distribution
of those that go through the hole as an extra factor $v$, compare to the speed 
distribution of gas molecules inside the box.

\subsection*{Average lifetime}
We first considering a molecule moving at speed $v$ with other molecules in
the gas stationary. Within a time $dt$, the molecule sweep through an area $\sigma v dt$,
where $\sigma$ is the collision cross-section of the molecule. We denote $P(t)$ as 
the probability of this molecule travel without any collision up to time $t$. We have:
\begin{align}
    P(t + dt) &= P(t) + \frac{dP}{dt}dt \\
    P(t + dt) &= P(t) (1 - n\sigma v dt) 
\end{align}
with $n$ the number density of gas and therefore $(1 - n\sigma v dt)$ gives the 
probability of having no other gas molecule in the volume the moving molecule is going 
to sweep over from time $t$ to $t + dt$. 
Withe the above two equation, we obtain the result:
\begin{equation}
    P(t) = e^{-n\sigma vt}
\end{equation}
We have the boundary condition $P(0) = 1$ and $P(\infty) = 0$

The probability that the molecule collide in time interval from $t$ to $t+dt$ is given by
the probability that molecule does not collide at time $t$ but do collide at time $t + dt$:
$P(t) - P(t + dt)$ (since P(t) decay with time, $dP(t) < 0$), we have:
\begin{equation}
    - dP(t) = n\sigma v e^{-n\sigma vt} dt
\end{equation}
We can calculate the mean scattering time:
\begin{align}
    \tau &= \int_{0}^{\infty} t n \sigma v e^{-n\sigma vt} dt \notag \\
         &= \frac{1}{n\sigma v} \int_{0}^{\infty} x e^{-x} dx \notag \\
         &= \frac{1}{n\sigma v}
\end{align}
where $x = n\sigma v t$ represent a change of variable.

In the case of hard sphere approximation in a gas consist of molecules with
equal radius, the collision cross-section is given as:
\begin{equation}
    \sigma = \pi (r_1 + r_2) ^ 2 = 4 \pi a^2
\end{equation}

\subsection*{Mean free path of gas}
With the previous result, we have, for the mean free path
\begin{equation}
    \lambda = \langle v \rangle \tau = \langle v \rangle \frac{1}{n\sigma \langle v_r\rangle }
\end{equation}
$\langle v \rangle$ is the average speed of gas molecules,
where for the lifetime, instead of using $v$, we recognize that we should use 
relative speed $v_r$ in a real system when all particles are in motion. It is not attempted to derive
the value of $\langle v_r\rangle$ here (refer to Blundell, p73). But the final result
is: 
\begin{equation}
    \lambda = \frac{1}{\sqrt{2}n\sigma}
\end{equation}

\section{Transport properties in Ideal gas}

\subsection*{Viscosity}
Viscosity $\eta$ measures th resistance of a liquid (gas) to deform by shear stress. Suppose we sandwich fluid between 
two infinitly large plate. We fix the bottom plate and apply some force $F$ to the top plate. The fraction between the fluid and 
the top plate will accelerate the fluid near it, the the momentum is passed down inside the liquid through internal interaction (collision)

Now, we wait for long enough time until the whole system is in equilibrium. The top plate will reach some final speed $u$ and 
the fluid near the top plate will have the same macroscopic speed (condition of equilibrium). The bottom plate and the fluid near the bottom 
will be stationary (An external force is necessary to keep the bottom plate stationary). 
Therefore, a velocity gradient will be set up in the fluid between the two plates (in $z$ direction). We define 
the viscosity by equation:
\begin{equation}
    \tau_{shear} = \frac{F}{A} = \eta \frac{d \langle u_x \rangle}{dz}
\end{equation}

With force $F$ constantly applied on the top plate, we are inputing momentum $Fdt$ per unit area in time $dt$. In equilibrium, 
These momentum will be transported completely to the bottom plate. Therefore, we have momentum flux through $z$ direction 
(note that the momentum itself is along the plate, $x$ dirction, but the flux is along $z$):
\begin{equation}
    \Pi_z = - F / A = - \eta \frac{d \langle u_x \rangle}{dz}
\end{equation}
We have a negative sign because the momentum flow from high velocity area to low velocity area, which is opposite the velocity gradient.

We can calculate the momentum flux by considering the microscopic motion of gas molecules. We consider that the motion of free ideal gas superimposed 
with the collective drifting motion with velocity $\langle u_z \rangle$. A molecules travelling along $z$ direction will
change their momentum by collision with other molecules in the final positon $z_2$ ($z_1 \to z_2$). The number of particle with velocity $v$ travelling
at an angle $\theta$ with $z$ direction is $ v\cos \theta n \cdot \frac{1}{2} f(v) dv \sin\theta d\theta $ per unit area $A$ and time $dt$. How far they 
travel will be given by the mean free path $\lambda$. The momentum difference of a molecule just after collision at $z_1$ and just after collision at $z_2$ is 
given by:
\begin{equation}
    - m \left( \frac{\partial \langle u_x \rangle}{\partial z} \right) \lambda \cos\theta
\end{equation}
which is the momentum flux created by this single molecule. Summing over all molecules with different speed and angle, we have:
\begin{align}
    \Pi_z &= \int_0^{\infty} dv \int_0^{\pi/2} d\theta 
     v \cos \theta n \frac{1}{2} f(v) \sin\theta \cdot m \left( \frac{\partial \langle u_x \rangle}{\partial z} \right) \lambda \cos\theta \\
     &= -\frac{1}{3} n m \lambda \langle v \rangle \frac{\partial \langle u_x \rangle}{\partial z} \label{momentum_transfer}
\end{align}
We obtain the viscosity:
\begin{equation}
    \eta = \frac{1}{3} n m \lambda \langle v \rangle
\end{equation}
Using the previous result $\lambda = (\sqrt{2}n\sigma)^{-1}$ and $\langle v \rangle = ()\frac{8k_BT}{\pi m})^{1/2}$, we can also write:
\begin{equation}
    \eta = \frac{2}{3\sigma}\left( \frac{mk_BT}{\pi} \right)^{1/2}
\end{equation}
We have the following observations:
\begin{enumerate}
    \item $\eta$ is independent of pressure.
    \item $\eta \propto T^{1/2}$.
    \item For the above approximation of momentum transfer to be correct, we require $ L \ll \lambda \ll d $, where $d$ is the size of the molecule and $L$ is the size scale of the container.
\end{enumerate}

\subsection*{Thermal conductivity}
We define the heat flux in the $z$ direction
\begin{gather}
    J_z = -\kappa \left( \frac{\partial T}{\partial z} \right) \\
    \mathbf{J} = -\kappa \nabla T
\end{gather}
The gas molecules carrier heat through their kinetic energy, which depend on temperature $T$ via $\langle E_k \rangle = 3k_BT / 2$. Defining heat capacity of a 
molecule as $C$, we can calculate the total heat flux:
\begin{align}
    J_z &= \int_0^{\infty} dv \int_0^{\pi/2} d\theta 
    v \cos \theta n \frac{1}{2} f(v) \sin\theta \cdot - C \left( \frac{\partial T}{\partial z} \right) \lambda \cos\theta \\
    &= -\frac{1}{3} n C \lambda \langle v \rangle \frac{\partial T}{\partial z} \label{heat_transfer}
\end{align}
Using $C_V = n C$, the thermal conductivity of gas is therefore
\begin{equation}
    \kappa = \frac{1}{3} C_V \lambda \langle v \rangle
\end{equation}

We observe that Eq.\ref{heat_transfer} is very similar to Eq.\ref{momentum_transfer}, and we have:
\begin{equation}
    \frac{\kappa}{\eta} = \frac{C}{m}
\end{equation} 

\subsection*{Particle Diffusion}
We consider a gas of molecules in which some of them is labelled, if those labelled molecules are initially confined in 
certain area and the confinement is removed, they will start to diffuse (Self-diffuse). Suppose that the diffusion is 
along $z$ direction and we use $n^*(z)$ to denote the density of those labelled particles, we can define the 
diffusion coefficient: 
\begin{equation}
    \Phi_z = -D \left( \frac{\partial n^*}{\partial z} \right)
\end{equation}
Following the above microscopic picture, we have:
\begin{align}
    \Phi_z &= \int_0^{\infty} dv \int_0^{\pi/2} d\theta 
    v \cos \theta \frac{1}{2} f(v) \sin\theta \cdot - \left( \frac{\partial n^*}{\partial z} \right) \lambda \cos\theta \\
    &= -\frac{1}{3} \lambda \langle v \rangle \frac{\partial T}{\partial z} 
\end{align}
giving the self-diffusion coefficient
\begin{equation}
    D = \frac{1}{3} \langle v \rangle
\end{equation}

We have the following relationship:
\begin{enumerate}
    \item $ D \propto T^{3/2}$
    \item $D \rho = \eta $, where $rho$ is the density $\rho = nm$
\end{enumerate}

\subsection*{Heat diffusion equation}
Given the heat flux $J = - \kappa \nabla T$, the total heat flow out of a closed surface $S$ is $\int_S J \cdot dS$.
This value should equal to the loss of total thermal energy $\int_V CT dV$, where $C$ here is the volume heat capacity. 
We have the Result:
\begin{equation}
    \int_S J \cdot dS = \int_V \nabla \cdot J dV = -\frac{\partial}{\partial t} \int_V CT dV
\end{equation}
where we obtain the first equality through divergence theorem. We have
\begin{align}
    \nabla \cdot J = -C \frac{\partial T}{\partial t} \\
    \frac{\partial T}{\partial t} = D \nabla^2 T \label{thermaldiffusion}
\end{align}
with $D = \kappa/C$ is the thermal diffusivity.
Eq.\ref{thermaldiffusion} is called \textbf{Thermal diffusion equation}.

In a steady state, we have $\partial T / \partial t = 0 $ so that the 
diffusion equation is reduced to 
\begin{equation}
    \nabla^2 T = 0
\end{equation}

Suppose we have a gas between two hot plates separate with a distance $L$, 
one maintained at temperature $T_1$ and the other at $T_2 < T_1$. By integrating
the equation $\partial^2 T / \partial x^2 = 0$ twice 
(note that this equation imply a linear temperature distribution)
and using the boundary condition,
we have:
\begin{equation}
    T = \frac{(T_2-T_1)x}{L} + T_1 
\end{equation}
The heat flux is given by:
\begin{equation}
    J = - \kappa \left( \frac{\partial T}{\partial x} \right) = \frac{\kappa}{L} (T_1 - T_2)
\end{equation}
The value $\kappa / L$ is called \textbf{thermal conductance}.

If heat is generated at a rate $H$ per unit volume, the divergence of $J$ will 
be:
\begin{equation}
    \nabla \cdot J = -C \frac{\partial T}{\partial t} + H
\end{equation}
and the thermal diffusion equation will be modified to be:
\begin{equation}
    \frac{\partial T}{\partial t} = D \nabla^2 T + \frac{H}{C}
\end{equation}

\subsection*{Thermal diffusion equation in 1D}
We want to solve the equation:
\begin{equation}
    \frac{\partial T}{\partial t} = D \frac{\partial^2T}{\partial x^2}
\end{equation}
to obtain the temperature profile.

Since this equation is a second order linear partial equation, we can look for 
wave-like solutions
\begin{equation}
    T(x,t) \propto \exp(i(kx - \omega t))
\end{equation}
with $k = 2\pi/\lambda $ and $\omega = 2\pi/f$ the wave vector and angular frquency. Solution is 
given by:
\begin{gather}
    - i \omega = -D k^2 \\
    k = \pm (1 + i) \sqrt{\frac{\omega}{2D}}
\end{gather}
Noting that with $ k = -(1 + i) \sqrt{\frac{\omega}{2D}}$, $T \to \infty$ as $x \to \infty$. 
Therefore, the solution for the temperature profile can be written as a summation of frequency:
\begin{equation}
    T(x,t) = \sum_{\omega} A(\omega)\exp(-i\omega t) \exp((i-1)\sqrt{\frac{\omega}{2D}}x) \label{thermaldiffusionsolution}
\end{equation}

As an application, consider solving the 1D problem of heat diffusion into the earth ground. The 
boundary profile is given by
\begin{equation}
    T(0,t) = T_0 + \Delta T \cos(\Omega t) = T_0 + \frac{\Delta T}{2} e^{i\Omega t} + \frac{\Delta T}{2} e^{-i\Omega t} \label{thermaldiffusionboundary}
\end{equation}
where the period is given by the alternation of day and night. 

Requiring Eq.\ref{thermaldiffusionsolution} to give the boundary condition Eq.\ref{thermaldiffusionboundary}, we obtain
the solution:
\begin{equation}
    T(x,t) = T_0 + \Delta T e^{-x/\delta} \cos(\Omega t - \frac{x}{\delta})
\end{equation}
where $\delta = \sqrt{2D/\Omega}$ is called the skin depth, and temperature fall off exponentially as $e^{-x/\delta}$.

\subsection*{Newton's law of cooling}
Newton's low of cooling states that the heat loss of a surface is proportional to the area of the surface
multiplied by the temperature difference. The heat flux is given by:
\begin{equation}
    J = h \Delta T
\end{equation}
with $h$ the heat transfer coefficient of the surface. As an example, suppose a cup of tea at temperature $T_{hot}$ 
is placed in a room at temperature $T_{air}$ and the heat loss is through the surface area $A$. Suppose the air temperature
near the surface is maintained at $T_{air}$ with convection, we have:
\begin{equation}
    -C \frac{\partial T}{\partial t} = J A  = h A (T - T_{air})
\end{equation}
$T(t)$ is the temperature of the tea. We have the solution
\begin{equation}
    T(t) = T_{air} + (T_{hot} - T_{air})e^{-\lambda t}
\end{equation}
with $\lambda = A h / C $

\subsection*{Prandtl number}
Apart from thermal diffusion, convection also play a part in the heat transfer in solid and gas. Convection will
dominate if momentum diffusion dominates. We can thus compare the magnititude of the two mechanism by
\begin{equation}
    \sigma_p = \frac{v}{D} = \frac{\eta c_p}{\kappa}
\end{equation}
where $v = \eta / \rho$ is the kinematic viscosity and $D$ is the thermal diffusivity $D = \kappa/(\rho c_p)$ ($c_p$ is the specific heat).
This value of called \textbf{Prandtl number}. For $\sigma_p \gg 1$, the convection is the dominant mode of heat transport. 
For gas, $\sigma_p$ can be found to be $2/3$ with the previous results. For liquid, $\sigma_p \gg 1$.

\section{Sound velocity in gas}
In fluids , only longnitudinal wave (compression) can be transitted. Transverse wave cannot be transitted since gas cannot transmit shear.
Speed of sound for a fluid can be derived from the \textbf{continuity equation} and \textbf{Euler equation}. 
The continuity equation for a fluid is:
\begin{gather}
    \int_S \rho \textbf{u} dS = \int_V \nabla\cdot(\rho \textbf{u}) dV = -\frac{\partial}{\partial t} \int_V \rho dV \label{continuity}\\
    \nabla\cdot(\rho \textbf{u}) = - \frac{\partial \rho}{\partial t}
\end{gather} 
where $\rho$ is the local fluid density, $S$ is the surface area of a volume element $V$ and $\textbf{u}$ is the 
local fluid velocity. The first term in Eq.\ref{continuity} is the flux through the surface, the second term is obtained 
by divergence theorem. In 1D, the equation is reduced to:
\begin{equation}
    \frac{\partial (\rho u)}{\partial x} = - \frac{\partial \rho}{\partial t}
\end{equation}

The Euler equation, on the other hand, determines the dynamics of a fluid, as:
\begin{gather}
    -\frac{1}{\rho} \nabla p = \frac{\partial \textbf{u}}{\partial t} + (\textbf{u} \cdot \nabla) \textbf{u} \\
    -\frac{1}{\rho} \frac{\partial p}{\partial x} = \frac{\partial u}{\partial t} + u \frac{\partial u}{\partial x}
\end{gather}

To obtain the velocity of sound in fluid in 1D, we expand the continuity equation and divide 
both side by $\rho$:
\begin{gather}
    \frac{u}{\rho} \pfrac{\rho}{x} + \pfrac{u}{x} = - \frac{1}{\rho} \pfrac{\rho}{t} \\ 
    \pfrac{u}{x} = - \frac{1}{\rho} \pfrac{\rho}{t}
\end{gather}
where we ignored the first term since it is second order ($u d\rho$). 
We also discard the second order term in the Euler equation and obtain:
\begin{gather}
    -\frac{1}{\rho} \frac{\partial p}{\partial x} = \frac{\partial u}{\partial t} \\
    - \frac{1}{\rho^2} \left( \rho \pfrac{P}{\rho} \right) \pfrac{\rho}{x} = \frac{\partial u}{\partial t} \\
    - \frac{B}{\rho^2} \pfrac{\rho}{x} = \frac{\partial u}{\partial t}
\end{gather}
where we used the definition of the Bulk modulus:
\begin{gather}
    B = -V \pfrac{p}{V} = \rho \pfrac{p}{\rho} \\
    \text{Using  } \ d\rho = M d\left( \frac{1}{V} \right) = - M \frac{dV}{V^2} = - \rho \frac{dV}{V}
\end{gather}
Now, using the result:
\begin{align}
    \pfrac{u}{x} &= - \frac{1}{\rho} \pfrac{\rho}{t} \\
    \frac{\partial u}{\partial t} &= - \frac{B}{\rho^2} \pfrac{\rho}{x}
\end{align}
and partial differentiate with respect to $t$ and $x$, we can remove $u$:
\begin{equation}
    - \frac{\partial^2 \rho}{\partial t^2} = - \frac{B}{\rho} \frac{\partial^2 \rho}{\partial x^2}
\end{equation}
which is a wave equation and the solution is given by:
\begin{equation}
    \rho \approx e^{i(kx-\omega t)}
\end{equation}
with propogating velocity:
\begin{equation}
    v_s = \frac{\omega}{k} = \sqrt{\frac{B}{\rho}}
\end{equation}

\subsection*{Sound velocity under isothermal and adiabatic conditions}
The difference between isothermal and adiabatic condition is whether temperature
or entropy (no relaxation process) is fixed during the transmission of the 
sound wave. In isothermal condition, we have:
\begin{equation}
    B_T = -V \left( \pfrac{p}{V} \right)_T = p
\end{equation}
so that the sound velocity is:
\begin{equation}
    v_s = \sqrt{\frac{B_T}{\rho}} = \sqrt{\frac{nm\langle v^2\rangle}{3\rho}} = \sqrt{\frac{\langle v^2\rangle}{3}}
\end{equation}
which coincide with the mean molecular speed in a given direction.

In the adiabatic condition, the gas obey:
\begin{equation}
    \frac{dp}{p} = -\gamma \frac{dV}{V}
\end{equation}
The adiabatic bulk modulus is then:
\begin{equation}
    B_S = -V \left( \pfrac{p}{V} \right)_S = \gamma p
\end{equation}
and the speed of sound is given by:
\begin{equation}
    v_s = \sqrt{\frac{\gamma\langle v^2 \rangle }{3}}    
\end{equation}

Since sound wave is passed by compressing and decompressing the fluid and as the fluid is compressed, their 
temperature will increase. Therefore,
The isothermal process is realized if there are enough time for thermal equilibration to take place.  
In the real case, the compression process is generally fast and the sound waves are almost always adiabatic.

\section{Brownian motion and fluctuations}
\subsection*{Brownian motion}
To study the Brownian
\footnote{Blundell, P390, we use the notion $\bar{x}$ for time average here, 
different from $\langle x \rangle$ used in the book}, 
we find the solution to the equation of motion (Langevin equation)
of a particle moving with random force:
\begin{equation}
    m\dot{v} = -\alpha v + F(t) \label{brownian_eom}
\end{equation}
where $\alpha$ is a damping constant due to friction. $F(t)$ is a random force with 
time average $\bar{F} = 0$.
In the absense of the random force, the solution will simply be:
\begin{equation}
    v(t) = v(0)\exp[-t/(m\alpha^{-1})]
\end{equation}
as an exponentially decrease of the velocity due to fraction.

To solve Eq.\ref{brownian_eom}, we multiply both size with $x$ and use the identity:
\begin{equation}
    \frac{d(x\dot{x})}{dt} = x \ddot{x} + \dot{x}^2
\end{equation}
and the equation of motion become:
\begin{equation}
    m \left( \frac{d(x\dot{x})}{dt} - m \dot{x}^2 \right) = - \alpha x \dot{x} + x F(t)
\end{equation}
We calculate the time average with the formula:
$ \overline{x} = \int_{t_1}^{t_2} x(t) dt / (t_2 - t_1)$
and the above equation becomes:
\begin{equation}
    m \frac{d}{dt} \overline{x\dot{x}} = m \overline{ \dot{x}^2 } 
    - \alpha \overline{ x \dot{x} } + \overline{ x F(t) }
\end{equation}
The final term equation to zero because the force is random. Assuming the 
system is in an thermal equilibrium and is ergodic, we can approximate:
\begin{equation}
    m \overline{ \dot{x}^2 } = m \langle \dot{x}^2\rangle = k_B T
\end{equation}
The final equation can be written:
\begin{equation}
    m \frac{d}{dt} \overline{x\dot{x}} = k_B T
    - \alpha \overline{ x \dot{x} } 
\end{equation}
The solution for $\overline{ x \dot{x} }$ is:
\begin{equation}
    \overline{ x \dot{x} } = C e^{-\alpha t/m} + \frac{k_B T}{\alpha}
\end{equation}

Now, we apply a boundary condition by choosing $x = 0$ when $t = 0$ 
(the motion of this molecular does not depend on this, the motion of the molecular
is the same before and after $t=0$, we are only choosing the origin $x = 0$ at this 
moment). Writing the ensemble average instead of time average, We obtain:
\begin{equation}
   \langle x \dot{x} \rangle = \overline{ x \dot{x} } = \frac{k_B T}{\alpha}( 1 - e^{-\alpha t/m})
\end{equation}
Using the identity $dx^2 / dt = 2x \dot{x}$, we have the result for the 
position at later time t:
\begin{equation}
    \langle x^2 \rangle = \overline{x^2} = \frac{2 k_B T}{\alpha}( t - \frac{m}{\alpha} e^{-\alpha t/m})
\end{equation}

For $t \gg m/a$, we have $ \langle x^2 \rangle = \frac{2k_B Tt}{\alpha} $. Using the diffusion 
constant $D$ as $ \langle x^2 \rangle = 2 D t $, we have: $ D = k_B T /\alpha $. This example is 
a example of fluctuation-dissipation theorem. Since $\alpha$ (dissipation) and $\langle x^2 \rangle$ 
(fluctuations) are inversely related.

\subsection*{Fluctuations}
We consider how a macroscopic properties $x$ deviate from the average
value. If a system is fixed at a given energy in a microcanonical ensemble, 
We write number of microstates by $\Omega(x,E)$. The entropy of the system
is thus:
\begin{equation}
    S(x,E) = k_B \ln \Omega(x,E)
\end{equation}
The probability of the system with property $x = x_i$ is then:
\begin{equation}
    p(x_i) \propto \Omega(x_i,E) = e^{S(x_i,E)/k_B T}
\end{equation}
The mean value will be given by condition $ (\partial S(x) /\partial x) |_{x_0} = 0$. If we 
Taylor expand $S(x,E)$ around $x_0$:
\begin{equation}
    S(x) = S(x_0) + \frac{1}{2}\left( \frac{\partial^2 S}{\partial x^2} \right)_{x_0} (x - x_0)^2 + \cdots
\end{equation}
The probability function is then a Gaussian:
\begin{equation}
    p(x) \approx \exp\left( - \frac{(\Delta x)^2}{2 \langle (\Delta x)^2 \rangle } \right)
\end{equation}
with the divation:
\begin{equation}
    \langle (\Delta x)^2 \rangle = - k_B / \left( \frac{\partial^2 S}{\partial x^2} \right)_{x_0}
\end{equation}

% \subsection{Availability}
% We can extend the above method to consider other ensembles, consider a ensemble 
% described by temperature, pressure and chemical potential. The change in entropy $dS$
% is related to the change in internal energy, volume and particle number by:
% I don't understand

\subsection{Kramers-Kronig relations}
We define the response function $\chi(t)$ as:
\begin{equation}
    \langle x(t) \rangle_f = \int_{-\infty}^{\infty} \chi(t-t') f(t') dt'
\end{equation}
We require the response function to be causal:
\begin{equation}
    \chi(t) = y(t)\theta(t)
\end{equation}
$y(t)$ is a function that coincide with $\chi(t)$ for $ t > 0 $ and 
we require $y(t) = - \chi(|t|)$ at $t < 0$. This definition ensures that the 
fourier transform of $y(t)$ is purely imaginary:
\begin{align}
    & \int_{-\infty}^{\infty} dt e^{-i\omega t} y(t) \\
    = & \int_{-\infty}^{\infty} dt [\cos(\omega t) - i \sin(\omega t)] y(t) \\
    = & -2i \int_{0}^{\infty} dt \sin(\omega t) y(t)
\end{align}
Here, the fourier transformation is defined to be:
\begin{gather}
    x(\omega) = \int_{-\infty}^{\infty} dt e^{-i\omega t} x(t) \notag \\
    x(t) = \frac{1}{2\pi} \int_{-\infty}^{\infty} d\omega e^{i\omega t} x(\omega) \notag \\
\end{gather}
and we have the relationship:
\begin{equation}
    \langle x(\omega) \rangle _f = \chi(\omega) f(\omega)
\end{equation}
The Fourier transformation of the response function is:
\begin{align}
    \chi(\omega) = & \int_{-\infty}^{\infty}  e^{-i\omega t}\theta(t) y(t) dt \notag \\
    = & \int_{-\infty}^{\infty}  e^{-i\omega t} \theta(t)  \left[ \frac{1}{2\pi}  \int_{-\infty}^{\infty} d\omega' e^{i\omega' t} y(\omega') \right] dt \notag \\
     = & \frac{1}{2\pi} \int_{-\infty}^{\infty} d\omega' \theta(\omega' - \omega) y (\omega') 
     \label{response_transform}
\end{align}

If the $\theta$ function is defined so that 
\begin{equation}
    \theta(t) = \lim_{\epsilon \to 0} 
    \begin{cases}
        e^{-\epsilon t}; & t > 0\\
        0; & t < 0
    \end{cases}
\end{equation}
Its fourier transformation is then given by:
\begin{equation}
    \theta(\omega) = \int_0^{\infty} dt e^{-i\omega t} e^{-\epsilon t}
    = \frac{1}{i\omega + \epsilon} 
    = \frac{\epsilon}{\omega^2 + \epsilon^2} - \frac{i\omega}{\omega^2 + \epsilon^2}
\end{equation}
taking the limit, we have:
\begin{equation}
    \theta(\omega) = \pi \delta(\omega) - \frac{i}{\omega}
\end{equation}
putting it into Eq.\ref{response_transform}, We have, for $\chi(\omega)$:
\begin{equation}
    \chi(\omega) = \frac{1}{2} y(\omega) - \frac{i}{2\pi} \mathcal{P} \int_{-\infty}^{\infty} 
    \frac{y(\omega')d\omega'}{\omega' - \omega}
    = \chi'(\omega) + i\chi''(\omega)
\end{equation}
Since $y(\omega)$ is purely real, we have the relationship:
\begin{gather}
    i\chi''(\omega) = \frac{1}{2} y(\omega) \\
    \chi'(\omega) = - \frac{i}{2\pi} \mathcal{P} \int_{-\infty}^{\infty} \frac{y(\omega')d\omega'}{\omega' - \omega}
\end{gather}
This gives the \textbf{Kramers-Kronig relations}:
\begin{equation}
    \chi'(\omega) = \frac{1}{\pi} 
    \mathcal{P} \int_{-\infty}^{\infty} \frac{ \chi''(\omega) }{\omega' - \omega}d\omega'
\end{equation}

Kramers-Kronig relation can also be derived from the fact that the response
function, now extending $\chi(\omega)$ to $\chi(z)$, is analytic in the upper
plane. The relationship follow directly from this condition. See \emph{Quantum Theory of 
Electron Liquid Page 127, 128}

As an example, we consider the response function of a damped harmonic oscillator 
with equation of motion:
\begin{equation}
    m \ddot{x} + \alpha \dot{x} + kx = f(t)
\end{equation}
writting $\omega_0^2 = k/m$ and $\gamma = \alpha/m$, we have:
\begin{equation}
    \ddot{x} + \gamma \dot{x} + \omega_0^2x = f/m
\end{equation}
Fourier transformation give the result:
\begin{equation}
    \chi(\omega) = \frac{x(\omega)}{f(\omega)} 
    = \frac{1}{m} \left[ \frac{1}{\omega_0^2 - \omega^2 - i\omega \gamma} \right]
\end{equation}
The imaginary part of the response function is given by:
\begin{equation}
    \chi''(\omega)  
    = \frac{1}{m} \left[ \frac{\omega \gamma}{(\omega^2 - \omega_0^2)^2 + (\omega \gamma)^2} \right]
\end{equation}
which vanish at $\omega \to 0$. The statis susceptibility is given by:
\begin{equation}
    \chi'(0) = \frac{1}{m\omega_0^2}
\end{equation}


\subsection{Correlation functions}
We define the autocorrelation function $C_{xx}(t)$ as a time average:
\begin{gather}
    C_{xx}(t) = \langle x(0)x(t) \rangle = \int_{-\infty}^{\infty} x^*(t')x(t'+t) dt' \\
    C_{xx}(\omega) = \int_{-\infty}^{\infty} e^{-i\omega t}\langle x(0)x(t) \rangle dt
\end{gather}
with $t=0$ we have the average of squred:
\begin{equation}
    \langle x^2 \rangle = 
    \frac{1}{2\pi} \int_{-\infty}^{\infty} C_{xx}(\omega) d\omega
\end{equation}

Note that the standard deviation can be written by: 
$\sigma^2 = \langle x^2 \rangle - \langle x \rangle ^2 $, if we take the average value
as $0$, than $\langle x^2 \rangle$ directly measure the fluctuation.

\subsection{Fluctuation-dissipation theorem}
We consider an example of harmonic system, its energy is given by: $E = kx^2 /2 $, where
$k$ is the string constants and $x$ is the amplitude of the vibration. In canonical 
ensemble, the probability of finding the system with amplitude $x$ is then given by:
\begin{equation}
    p(x) = \mathcal{N}' e^{-\beta(kx^2/2)}
\end{equation}
which is an Gaussian form with mean $\langle x \rangle = 0$ and deviation
$\langle x^2 \rangle = \sigma^2 = 1/(\beta k)$. 

Now, if we apply a force $f$ on the oscillator, its energy will be modified:
$E = kx^2/2 - xf$. The probability distribution became:
\begin{equation}
    p(x) = \mathcal{N}' e^{-\beta(kx^2/2 - xf)} = \mathcal{N}'' e^{-\frac{\beta k}{2} (x - \frac{f}{k})^2 }
\end{equation}
where we completed the squre in the exponentially and add the additional 
factor into $\mathcal{N}''$. 

This is an Gaussian distribution with mean value: $\langle x \rangle_f = f/k$ and 
deviation $1/(\beta k) = \langle x^2 \rangle$. (where $\langle x^2 \rangle$ refer to the 
deviation of the undisturbed system). 
We have the relationship:
\begin{equation}
    \frac{\langle x \rangle_f}{\langle x^2 \rangle} = \beta f
\end{equation}
The mean value of $x$ can also be expressed by $\langle x \rangle_f = \chi(0)' f $
(The imaginary part $\chi''(0) = 0$). Then we have the result:
\begin{equation}
    \langle x^2 \rangle = k_B T \chi(0)' = 
    k_BT\int_{-\infty}^{\infty} \frac{d\omega'}{\pi} \frac{\chi''(\omega')}{\omega'} 
\end{equation}
This is the statement of the fluctuations dissipation theorem, connecting the 
fluctuation (autocorrelation function) to the imaginary part of the response function.

\section{Non-equilibrium thermodynamics}
\subsection*{Irreversibility of transport process}
We have the following relationship between local entropy density, local energy $u$, particle density and 
charge density:
\begin{gather}
    ds = \frac{1}{T} du - \frac{\mu}{T} dn + \frac{\phi}{T} d\rho_e \\
    ds = \sum_k \phi_k d\rho_k
\end{gather}
where in the second equation, we generalize all possible contribution to a local entropy change 
with a generalized potential $\phi_k = \partial s / partial \rho_k$ and a generalized density $\rho_k$. 
(For example, with $\rho_k = u$ we have $\phi_k = 1/T$). 
Since the generalized density are conserved in the system, we have the continuous equation relating the 
change of $\rho$ with respect to the current:
\begin{equation}
    \pfrac{\rho_k}{t} + \nabla \cdot \mathbf{J}_{k} = 0
\end{equation}

We can calculate the local change in entropy and the flow of entropy:
\begin{gather}
    \pfrac{s}{t} = \sum_k \phi_k \pfrac{\rho_k}{t} \\
    \mathbf{J}_s = \sum_k \phi_k \mathbf{J}_{k}
\end{gather}
We find the following result:
\begin{align}
    \Sigma &= \pfrac{s}{t} +\nabla \cdot  \mathbf{J}_s \\
    & = \sum_k \phi_k \pfrac{\rho_k}{t} + \nabla \cdot \left(\sum_k \phi_k \mathbf{J}_{k} \right)\\
    & = \sum_k \phi_k \pfrac{\rho_k}{t} + \sum_k (\nabla  \phi_k) \mathbf{J}_{k} + \sum_k \phi_k (\nabla \cdot \mathbf{J}_{k}) \\
    & = \sum_k \phi_k \pfrac{\rho_k}{t} + \sum_k (\nabla  \phi_k) \mathbf{J}_{k} - \sum_k \phi_k \pfrac{\rho_k}{t} \\
    & = \sum_k \nabla \phi_k \mathbf{J}_{k}
\end{align}
Which gives the generation rate of entropy per unit volume.

We further consider the current of the generalized density to be a linear response to the 
gradient to the respective potential:
\begin{equation}
    \mathbf{J}_i = \sum_j L_{ij} \nabla \phi_j \label{linearresponse}
\end{equation}
where index $i,j$ denote different components and $L$ is called kinetic coefficient. 

As an example, for thermal conduction $\mathbf{J}_u = - \kappa \nabla T$, we have 
the $\mathbf{J}_u = \kappa T^2 \nabla (1/T)$ for the potential $1/T$. $L_uu = \kappa T^2$.
Using Eq.\ref{linearresponse}, we obtain the entropy generation rate:
\begin{align}
    \Sigma &= \sum_k \nabla \phi_k \sum_j L_{kj} \nabla \phi_j \notag \\
        & = \sum_{kj} \nabla \phi_k L_{kj} \nabla \phi_j
\end{align}

For the local entropy, we require it to increase monotonically in an irreversible process. Therefore,
$\Sigma > 0$ and $L$ is positive definitive.

\subsection*{Onsager's reciprocal relation}
We consider a system that is near an equilibrium state, we define the 
variable $\alpha_k = \rho_k - \rho_k^0$ the departure of the $k^{th}$ density
variable. Writing $\alpha = (\alpha_1, \cdots, \alpha_m)$, we can write 
the probability distribution:
\begin{gather}
    P(\alpha) \propto e^{\Delta S/k_B} \\
    \Delta S = -\frac{1}{2} \sum_{ij} g_{ij} \alpha_i \alpha_j \\
    g_{ij} = \left( \frac{\partial^2S}{\partial \alpha_i \partial \alpha_j} \right)_{\alpha=0}
\end{gather}
We have the relationship:
\begin{equation}
    \pfrac{\ln P}{\alpha_i} = \frac{1}{k_B} \frac{\partial S}{\partial \alpha_i} 
    = \frac{1}{k_B} \sum_j g_{ij} \alpha_j \label{tmp}
\end{equation}

We can derived the following relationship:
\begin{align}
    \left\langle \pfrac{S}{\alpha_i} \alpha_j \right\rangle 
    = k_B \left\langle \pfrac{\ln P}{\alpha_i} \alpha_j \right\rangle \notag \\
    = k_B \int \pfrac{\ln P}{\alpha_i} \alpha_j P(\alpha) d\alpha \notag \\
    = k_B \int \pfrac{P}{\alpha_i} \alpha_j  d\alpha \notag \\
    = k_B \left( \int [P\alpha_j]_{\alpha_j = -\infty}^{\infty}  d\alpha' - \int \pfrac{\alpha_j}{\alpha_i} P d\alpha \right)\notag \\
\end{align}
where we integrate by parts for variable $d\alpha_i$ and $d\alpha'$ removes $d\alpha_i$ from $d\alpha$. The 
first term is 0 since $P(\alpha_j \to \infty) = 0$. We have the final relationship:
\begin{equation}
    \left\langle \pfrac{S}{\alpha_i} \alpha_j \right\rangle  = - k_B \int \pfrac{\alpha_j}{\alpha_i} P d\alpha = -k_B \delta_{ij}
    \label{derive}
\end{equation}
where we use $\partial \alpha_j / \partial \alpha_i = \delta_{ij}$ and the fact that $P$ is normalized to 1.

We now make an important assumption of \textbf{microscopic reversibility}, which 
states:
\begin{align}
    \langle \alpha_i(0)\alpha_j(t) \rangle &= 
    \langle \alpha_i(0)\alpha_j(-t) \rangle \notag \\ 
    &= \langle \alpha_i(t)\alpha_j(0) \rangle
\end{align}
We thus find:
\begin{gather}
    \langle \alpha_i(0)\alpha_j(t) \rangle - \langle \alpha_i(0)\alpha_j(0) \rangle  
    = \langle \alpha_i(t)\alpha_j(0) \rangle - \langle \alpha_i(0)\alpha_j(0) \rangle   \notag \\
    \langle \alpha_i \dot{\alpha}_j \rangle = \langle \dot{\alpha}_i \alpha_j \rangle \label{microreverse}
\end{gather}
where we divided time $t$ and take the limit $t \to 0$.

We now make the consideration that $\dot{\alpha}$ is linear porpotional to $\alpha$:
\begin{equation}
    \dot{\alpha}_i = \sum_j \lambda_{ij} \alpha_j
\end{equation}
with Eq.\ref{tmp}, we find:
\begin{equation}
    \dot{\alpha}_i = \sum_{j} \left( \frac{\lambda}{g} \right)_{ij} \frac{\partial S}{\partial \alpha_j} 
\end{equation}
where the fraction is the matrix division. Substituting the above equation to Eq.\ref{microreverse}, we have:
\begin{equation}
    \sum_{k} \left( \frac{\lambda}{g} \right)_{jk} \left\langle \alpha_i \frac{\partial S}{\partial \alpha_j} \right\rangle
    = \sum_{k} \left( \frac{\lambda}{g} \right)_{ik} \left\langle \frac{\partial S}{\partial \alpha_k} \alpha_j \right\rangle
\end{equation}
Using Eq.\ref{derive}, we have:
\begin{equation}
    \left( \frac{\lambda}{g} \right)_{ij} = \left(  \frac{\lambda}{g} \right)_{ji}
\end{equation}
Now, taking $L \propto \lambda / g$, we obtain the Onsager reciprocal relations:
\begin{equation}
    L_{ij} = L_{ji}
\end{equation}

\pagebreak
\section*{Appendix A: Time average and ensemble average}
\subsection*{Definition}
In a system with random fluctuations
\footnote{This content is from \url{https://www.nii.ac.jp/qis/first-quantum/e/forStudents/lecture/pdf/noise/chapter1.pdf}}, 
one can only discuss the averaged quantity of a single system over a certain
time (space) interval or averaged quantity of many identical systems at certain 
time instance (spatial positions). The former is called \textbf{time average} and 
the later is called \textbf{ensemble average}. 

Let's consider N systems which have time dependent observable $x^{i}(t)$, where
i index the system. We can define the following averages: \\
First-order time average: 
\begin{equation}
    \overline{x^i(t)} = \lim_{T\to\infty} \frac{1}{T} \int_{-T/2}^{T/2} x^i(t) dt
\end{equation}
Second-order time average:
\begin{equation}
    \overline{x^i(t)^2} = \lim_{T\to\infty} \frac{1}{T} \int_{-T/2}^{T/2} \left( x^i(t) \right)^2 dt
\end{equation}
Autocorrelation function:
\begin{equation}
    \phi_x^i(\tau) = \overline{x^i(t)x^i(t+\tau)} 
    = \lim_{T\to\infty} \frac{1}{T} \int_{-T/2}^{T/2} x^i(t) x^i(t+\tau) dt
\end{equation}
First-oder ensemble average:
\begin{equation}
    \langle x(t_1) \rangle = \lim_{N\to\infty} \frac{1}{N} \sum_{i=1}^{N} x^i(t_1) 
        = \int_{-\infty}^{\infty} x_1 p_1(x_1, t_1) dx_1
\end{equation}
Second-order ensemble average:
\begin{equation}
    \langle x(t_1)^2 \rangle = \lim_{N\to\infty} \frac{1}{N} \sum_{i=1}^{N} \left( x^i(t_1) \right)^2  
        = \int_{-\infty}^{\infty} \left( x_1(t) \right)^2  p_1(x_1, t_1) dx_1
\end{equation}
Covariance:
\begin{equation}
    \langle x(t_1)x(t_2) \rangle = \lim_{N\to\infty} \frac{1}{N} \sum_{i=1}^{N}  x^i(t_1) x^i(t_2)
        = \int_{-\infty}^{\infty} x_1 x_2 p_2(x_1, t1; x_2, t_2) dx_1 dx_2
\end{equation}
where for esemble average, $t_1$ and $t_2$ refer to a certain time. $p(x,t)$ is the 
probability density function so that $p_1(x_1,t_1)dx_1$ is the 
first-order probability that $x$ is found between $x_1$ and $x_1 + dx_1$ at time $t_1$. 
$p_2(x_1, t_1; x_2, t_2)dx_1 dx_2$ is the probability that $x$ is between $x_1$ and $x_1 + dx_1$
at time $t_1$ and between $x_2$ and $x_2 + dx_2$ at a different time $t_2$.

\subsection*{Statistically stationary and nonstationary process}
A "process" refers to the trajectory of a system as it evolve through time. If the 
statistics of the process of a system do not change in time, we call such 
process stationary. The ensemble average of system with stationary process 
are identical to its time average. Such process is called \textbf{ergodic}.
When a process is ergodic, any one system can represent the entire ensemble. 

We make the following definition:
\emph{A stochastic process is stationary of order $k$ if the $k$-th order 
joint probability density function satisfies:}
\begin{equation}
    P(\alpha_1,t_1; \cdots; \alpha_k, t_k) = P(\alpha_1,t_1+\epsilon; \cdots; \alpha_k, t_k+\epsilon)
\end{equation}
for all $\epsilon$, where $\alpha$ denote some observables.
For example, if $P_1(x,t_1) = P_1(x,t_1+\epsilon)$, the process is stationary of order 1.
if $P_2(x_1,t_1;x_2,t_2) = P_2(x_1,t_1+\epsilon;x_2,t_2+\epsilon)$, 
the process is stationary of order 2.

A process of the system is called "strictly stationary" if it is stationary for any order.
A process is called "wide-sense stationary" if its mean value is constant and its 
autocorrelation function depends only on $\tau = t_2 - t_1$. 

/subsection*{Ergodicity}

Ergodicity can also have different levels: We call a process "ergodic in the mean" if
\begin{equation}
    \overline{x(t)} = \lim_{T\to\infty} \frac{1}{T} \int_{-T/2}^{T/2} x(t) dt
     = \langle x(t) \rangle
\end{equation}
since $\overline{x(t)}$ is independent of time, $\langle x(t) \rangle$ is also independent of time.
which is ensured by the probability density function requirement of stationary process
$P_1(x,t_1) = P_1(x,t_1+\epsilon)$. 
A process is called ergodic in the autocorrelation if 
\begin{equation}
    \phi_x(\tau) = \overline{x(t)x(t+\tau)} 
    = \lim_{T\to\infty} \frac{1}{T} \int_{-T/2}^{T/2} x(t) x(t+\tau) dt
     = \langle x(t)x(t+\tau) \rangle \label{autocorrelation_requirement}
\end{equation}

As an example, consider some observable of a system that can be written as a 
function of time by $x(t) = sin(\omega t + \theta)$. $\theta$ is a random variable 
distributed over $0 < \theta < 2\pi$. 
This process is ergodic in both mean and autocorrelation. The time average $\overline{x(t)}$
is 0, the ensemble average at any time is also 0, averaged over system with different 
choice of $\theta$. Eq.\ref{autocorrelation_requirement} is also satisfied since both 
$\overline{x(t)x(t+\tau)}$ and $\langle x(t)x(t+\tau) \rangle$ vanish, since $x$ depend
on time through a $\sin$ function and can increase or decrease after a time interval $\tau$
(time average) and from the choice of $\theta$,
both case average to 0. 
However, if we limit the variable $\theta$ to other distribution, this process will no longer 
be ergodic.

\end{document}
