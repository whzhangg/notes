\documentclass{article}
\usepackage{amsmath}
\usepackage[margin=0.8in]{geometry}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{hyperref} % \url \href

\newcommand{\pfrac}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\dbar}{d}
\newcommand{\dnor}{\text{d}}
% \renewcommand{\H}{\mathcal{H}}

\begin{document}

\title{Law of Thermodynamics}
\author{Wenhao}
\date{\today}
\maketitle

\section{First Law}
Suppose we have the function $f(x)$, where $x$ are parameters of the state. 
If the integral:
\begin{equation}
    \Delta f = \int_{x_i}^{x_f} df = f(x_f) - f(x_i) 
\end{equation}
i.e., if $\Delta f$ is independent of the path chosen, then we call $f$ a 
\textbf{function of state}, which only depend on the system parameter at a 
certain instance.

\textbf{Equation of states} are equation that contain only function of states:
i.e., for ideal gas, we have $pV = RT$ which depend on $p, V, T$, all of them are 
function of states.

\textbf{First law}: energy is conserved in the form of heat and work.

Writting $U$ as the internal energy, The equation of states can be written as
\begin{gather}
    \Delta U = \Delta Q + \Delta W \\
    \dnor U = \dbar Q + \dbar W = \dbar Q - \dnor dV
\end{gather}
where $\Delta$ gives the total change and $\dnor$ represent differential change. $\dbar$
represent changes that are path dependent. It is clear that 
the heat absorbed and the work done to the system depend on the specific process, and 
thus they cannot be exact differentiated with respect to the system parameters, while 
volume $V$ is a function of states.

\subsection*{Heat capacitiy of gas at constant volume or pressure}
For ideal gas, we have:
\begin{align}
    \dbar Q &= \dnor U + p \dnor V \\
    \dbar Q & = \left(\pfrac{U}{T}\right)_V \dnor T + \left(\pfrac{U}{V}\right)_T \dnor V + p \dnor V \\
    \frac{\dbar Q}{\dnor T} &= \left(\pfrac{U}{T}\right)_V + \left[ \left(\pfrac{U}{V}\right)_T  + p \right] \frac{\dnor V}{\dnor T}
\end{align}
Therefore, at fixed volume, $\dnor V = 0$ and we have:
\begin{equation}
    C_V = \left(\frac{\dbar Q}{\dnor T}\right)_V = \left(\pfrac{U}{T}\right)_V
\end{equation}
at fixed pressure:
\begin{align}
    C_p & = \left(\frac{\dbar Q}{\dnor T}\right)_p \\
        & = C_V + \left[ \left(\pfrac{U}{V}\right)_T  + p \right] \left(\frac{\dnor V}{\dnor T}\right)_p
\end{align}
For ideal gas, we have $\left(\pfrac{U}{V}\right)_T = 0$. and $p \left(\frac{\dnor V}{\dnor T}\right)_p = R$,
so that we have: $C_p = C_V + R$. For an equilibrium gas at constant pressure, the volume of the gas also expand when
the temperature of the gas is increased (gas do work to the environment). 
So we in generally need to input more heat to the increase the temperature of the gas, compared to the case of constant 
volume. 

In general gas, we define the ratio $\gamma$ called \textbf{adiabatic index}:
\begin{equation}
    \gamma = \frac{C_p}{C_V}
\end{equation}


\section{Second Law}

\subsection*{Reversible process}
we define a process to be reversible if \textbf{at every moment during the process, the system
is in equilibrium}. As an example, for an ideal gas, if the equation of state $pV = RT$ is hold true
at every moment during the process, then it implies that the gas is always in an equilibrium state
and the process is reversible: If this process is reversed we could not notice. 
We consider two types of reversible process in terms of gas: First is called \textbf{Isothermal process}
and the second is called \textbf{Adiabatic process}.

In the isothermal process, the temperature of the system is fixed:
\begin{equation}
    \Delta T = 0
\end{equation}
For ideal gas, this implies that $\Delta U = 0$, for reversible process of ideal gas, The 
equation of states is always true. This gives:
\begin{gather}
    \Delta U = \dbar Q - \frac{RT}{V} \dnor V = 0 \\
    \Delta Q = \int_{V_1}^{V_2} \dbar Q = \int_{V_1}^{V_2} \frac{RT}{V} \dnor V = RT \ln \frac{V_2}{V_1}
\end{gather}

In the adiabatic process, the system is not allowed to exchange heat with the 
environment, thus we have $\dbar Q = 0$. We find:
\begin{gather}
    \dnor U = \dbar W \\
    C_V dT = - p \dnor V = - \frac{RT}{V} \dnor V \\
    \ln \frac{T_2}{T_1} = - \frac{R}{C_V} \ln \frac{V_2}{V_1}
\end{gather}
For ideal gas, $C_p = C_V + R$, $\gamma = 1 + R / C_V$ and we find:
\begin{gather}
    \ln \frac{T_2}{T_1} = (1-\gamma) \ln \frac{V_2}{V_1} \\
    \frac{T_2}{T_1} = \left( \frac{V_2}{V_1} \right) ^ {1-\gamma} = \left( \frac{V_1}{V_2} \right) ^ {\gamma-1} \\
    T V^{\gamma - 1} = \text{const} \\
    p V^{\gamma} = \text{const}
\end{gather}
where we used relationship $pV = RT$ to obtain the last relationship. Equation $p V^{\gamma}$ 
enable us to find the pressure of the system if we know the volume of the 
system during a adiabatic expansion or compression. Temperature can be derived using the ideal 
gas law then, if we know the pressure and volume.

\subsection*{second law}
The second law can be stated in the following two equivalent form:

\textbf{Clausius statement} No process whose sole effect is to transfer heat from cold to hot body

\textbf{Kelvin statement} No process is possible whose sole effect is to convert heat into work

It is important to note the work "sole effect". For example, in an isothermal process of ideal gas, 
$\dbar Q + \dbar W = 0$ so all the heat is converted into work done by the system. However, the 
accompanying effect is that the volume of the gas expanded. 
Therefore, To study the ability to convert heat into work, we should consider process which has no 
other effect other than the conversion, such as Carnot engine which work in cycles

\subsection*{Carnot engine}
We define a carnot engine which consist of two reversible adiabatic and two reversible 
isothermal process, working between temperature $T_h$ and $T_l$. The carnot engine do work
in the following process:

\begin{table*}
    \centering
    \begin{tabular}{ccc}
        $ A \to B $ & isothermal expansion & $Q_h = RT_h \ln \frac{V_B}{V_A}$ \\
        $ B \to C $ & adiabatic & $ \frac{T_h}{T_l} = \left( \frac{V_C}{V_B} \right) ^ {\gamma-1} $ \\
        $ C \to D $ & isothermal compression & $Q_l = - RT_h \ln \frac{V_D}{V_C}$ \\
        $ D \to A $ & adiabatic & $ \frac{T_h}{T_l} = \left( \frac{V_D}{V_A} \right) ^ {\gamma-1}$ \\
    \end{tabular}
\end{table*}

The adiabatic process lead to $\frac{V_C}{V_B} = \frac{V_D}{V_A} $, with $V_B > V_A$. Finally, we 
find the important result for a carnot energy:
\begin{gather}
    \frac{Q_h}{T_h} = \frac{Q_l}{T_l} \\
    Q_h - Q_l = W
\end{gather}
where $W$ is the work done in one carnot cycle. We can find the efficiency of the engine
\footnote{This carnot engine seems to convert all the heat absorbed into work, $Q_h - Q_l \to W$. But
it has the additonal effect to transport heat from one source to another. Therefore, this does not 
conflict with Kelvin's statement}:
\begin{equation}
    \eta = \frac{W}{Q_h} = 1 - \frac{T_l}{T_h}
\end{equation}

We have the following statement related to the (reversible) carnot engines:
\begin{itemize}
    \item Carnot engine is the most efficient engine
    \item all reversible engine operating at the same temperature environment have the same efficiency
    \item Clausius statement of the second law is the same as Kelvin's statement \footnote{See book}
\end{itemize}

\subsection*{Refrigerator}
We consider the above carnot energy run backwards: it absorb heat $Q_l$ from the 
low temperature side with an isothermal expansion. Input work $W$ is provided 
during the adiabatic process, and dump heat $Q_h$ into the the hot side 
with an isothermal compression process. The result for such a refrigerator is:
\begin{gather}
    Q_l + W = Q_h \\
    \frac{Q_h}{T_h} = \frac{Q_l}{Q_l} \\
    \eta = \frac{Q_l}{W} = \frac{T_l}{T_h - T_l}
\end{gather} 

\subsection*{Clausius theorem}
Suppose we have a seriers of heat exchange in a working cycle of an engine. At 
each step, the engine exchange heat $\dbar Q_i $ from a \textbf{contact} with 
temperature $T_i$. The maximum work this engine can produce is then:
\begin{equation}
    \Delta W = \sum_i \dbar Q_i
\end{equation}

Furthermore, each of these contact are connect to \textbf{a single environment} 
with temperature $T$ through a carnot cycle. Each of these carnot cycle can be considered
as heat pumps or refrigerators, which operates to provide (absorb) heat $\dbar Q_i $
at each contact.
We have the relationship for these carnot cycles:
\begin{gather}
    \frac{\dbar Q}{T} = \frac{\dbar Q_i}{T_i} \\
    \dbar Q = \dbar Q_i + \dbar W_i 
\end{gather}

Since this system work in cycles, it cannot absorb heat from a single heat resevior (environment at $T$) 
and output work (second law). So the total work output by this system is necessary zero (do nothing) or negative 
(external work need to be provided to get this system going). So we have the following requirement:
\begin{equation}
    \sum_i \dbar W_i + \Delta W \le 0
\end{equation}
We have:
\begin{gather}
    \dbar W_i = \dbar Q - \dbar Q_i = \dbar Q_i (\frac{T}{T_i} - 1) \\
    \Delta W = \sum_i \dbar Q_i 
\end{gather}
So we can find:
\begin{gather}
    \sum_i \dbar Q_i \frac{T}{T_i} \le 0 \\
    \sum_i \frac{\dbar Q_i}{T_i} \le 0 \ \ \text{or}\ \  \oint \frac{\dbar Q}{T} \le 0
\end{gather}
The second equation is the result of the Clausius theorem. The equal sign is only achieved for a reversible energy,
which we write:
\begin{equation}
    \oint \frac{\dbar Q_{rev}}{T} = 0
\end{equation}

\subsection*{entropy}
For an reversible process, we have the relationship:
\begin{equation}
    \oint \frac{\dbar Q_{rev}}{T} = 0
\end{equation}
suggesting that the integral:
\begin{equation}
    \int_{A}^{B} \frac{\dbar Q_{rev}}{T} \ \ \text{is path independent}
\end{equation}
We therefore define a value $\dnor S = \dbar Q_{rev} / T$ and the value 
of $S$ is an function of state. $S$ is called the entropy. 
For adiabatic process, $\dbar Q = 0$ and $\dnor S = 0$

In general, we consider a general cycle consists of both reversible and 
irreversible process. According to Clausius theorem, we have:
\begin{equation}
    \oint \frac{\dbar Q}{T} = \int_A^B \frac{\dbar Q}{T} + \int_B^A \frac{\dbar Q_{rev}}{T} \le 0
\end{equation}
so that we have:
\begin{equation}
    \int_A^B \frac{\dbar Q}{T} \le \int_A^B \frac{\dbar Q_{rev}}{T} = \int_A^B \dnor S
\end{equation}
taking the process from $A$ to $B$ infinitsemial, we thus find:
\begin{equation}
    \frac{\dbar Q}{T} \le \dnor S
\end{equation}
and the equality only happens for reversible process.

In thermally isolated system, $\dbar Q = 0$, and we reach an
important conclusion that for such isolated system, the entropy
of the system can only increase: $ \dnor S \ge 0$.

For a reversible process, $\dbar Q = T \dnor S$ and the first law gives:
\begin{align}
    \dnor U & = T \dnor S + \dbar W \\
            & = T \dnor S - p \dnor V \label{internal energy}
\end{align}
Since value $U, T, S, p, V$ are all function of state. This 
result is independent of the process and also holds for 
irreversible process.
For an irreversible process, $\dnor U = \dbar Q + \dbar W$
but:
\begin{gather}
    \dbar Q \neq  T \dnor S \\
    \dbar W \neq  - p \dnor V 
\end{gather}
but 
\begin{equation}
    \dbar Q + \dbar W = \dbar Q_{rev} - p \dnor V = T \dnor S - p \dnor V
\end{equation}

Equation.\ref{internal energy} also give the result:
\begin{gather}
    p = - \left(\frac{\dnor U}{\dnor V}\right)_S \\
    T = \left(\frac{\dnor U}{\dnor S}\right)_V
\end{gather}

\subsection*{Joule Expansion}
We consider a process of Joule expansion as an example of irreversible process:
suppose a container is separate into half, each with volume $V_0$. The gas is 
initially confined one side of the container with pressure $p_i$. The other side
of the container is vacuum. Now we remove the separation and let the 
gas take up the volume of the whole container.

We have the equation of states:
\begin{gather}
    p_i V_0 = RT_i \\
    p_f 2V_0 = RT_f
\end{gather}
since the internal energy of the gas does not change, $\Delta U = 0$ and therefore 
for ideal gas, its temperature remain the same: $T_i = T_f$. We thus have:
$p_f = \frac{1}{2} p_i$. and
\begin{gather}
    \dnor U = T \dnor S - p \dnor V = 0 \\
    \dnor S = \frac{p}{T} \dnor V \\ 
    \Delta S = \int_i^f \dnor S = \int_i^f \frac{p}{T} \dnor V = \int_i^f \frac{R}{V} \dnor V = R \ln2
\end{gather}
where we consider the process as a reversible isothermal expansion, but is since $S$ is function
of state, the result is true for any process
\footnote{
Joule expansion is associated with Maxwell's Demon, which is an interesting read at page 149 of the book
}.

\subsection*{Entropy of macrostates and total entropy}
Since we have the statistical definition of temperature
\begin{equation}
    \frac{1}{k_BT} = \frac{\dnor \ln\Omega}{\dnor E}
\end{equation}
where $\Omega$ is the number of microstates with energy $E$. 
Assume a microcanonical ensemble (each microstates have the same energy
and are equally probably), then the internal energy coinside 
with energy $E$. Using the relation:
\begin{equation}
    T = \left( \pfrac{U}{S} \right)_V
\end{equation}
We find the result:
\begin{equation}
    S = k_B \ln \Omega
\end{equation}
which we call the Boltzmann's definition of entropy
\footnote{\url{https://physics.stackexchange.com/questions/141321/what-is-the-conceptual-difference-between-gibbs-and-boltzmann-entropies}}.

Now, we consider ensembles other than microcanonical ensemble. Suppose the system 
have in total N possible microstates of equal probability, 
which can be divided into $i$ macrostates that we can distinguish by experimental measurement.
Each of those macrostates contain $n_i$ microstates. We define the Gibb's entropy:
\begin{equation}
    S_{tot} = S + S_{micro}
\end{equation}
where $ S_{tot} = k_B \ln N$. The microscopic entropy is given by:
\begin{equation}
    S_{micro} = \langle S \rangle = \sum_i P_i S_i = \sum_i P_i k_B\ln n_i
\end{equation}
where the probability $p_i = n_i / N$ and $\sum_i p_i = 1$. We have:
\begin{align}
    S & = k_B \left(\sum_i p_i\right) \ln N - \sum_i P_i k_B\ln n_i \\
    & = - k_B \sum_i p_i \ln p_i
\end{align}

Gibbs entropy formula is useful because we can generally measure the probability 
distribution is macroscopic distinguishable states and calculate the entropy from 
the probability distribution, while for Boltzmann's definition of entropy, it's only
applicable for microcanonical ensemble and we cannot access the actual number 
of the microstates.

\section{Third Law}
We can measure the change of entropy of a system by measuring its heat capacitiy:
\begin{gather}
    C_p = T\left(\pfrac{S}{T}\right)_p \label{thirdlawcp}\\
    S = \int \frac{C_p}{T} \dnor T
\end{gather}
so that we have:
\begin{equation}
    S(T) = S(T_0) + \int_{T_0}^{T} \frac{C_p}{T} \dnor T
\end{equation}

The third law states that the entropy of a system at absolute zero will be zero:

\textbf{Planck's statement of the third law} The entropy of all systems in internal
equilibrium is the same at absolute zero and may be taken to be zero.

It is noted that the system should be in a relaxed internal equilibrium, it is possible,
for example, to freeze a metastable glass phase instead of a crystalline phase and go down
o $T \to 0$ with non zero entropy.

As a consequence of the third law, Heat capacitiy, given by Eq.\ref{thirdlawcp} will
necessarily go to zero as $T\to0$.

As another implication, Using the statistical definition of the entropy $S = k_B \ln \Omega$
implies that the ground states of a system at absolute zero, is necessary non-degenerate with
$\Omega = 1$ so that the entropy will be zero. Such non-degeneracy would be enforced by the 
third law for real systems, as well as the requirement for $C_pto 0$. 
As an example, the curie's law gives a susceptibility $\chi \to \infty$ as $T \to 0$. But with
the third law, we require $\partial \chi / \partial T \to 0$. This problem is caused because
for Curie law, we assumed a mean field interaction where the interaction of magnetic
moment is ignored\footnote{See discussion in page 204-205}. 

\section{Thermodynamic potentials}
We call \textbf{Thermodynamic potentials} functions that are constructed from 
the functions of state. 
We define the following Thermodynamic potentials, The first being the internal 
energy, the following are the Enthalpy, Helmholtz function and the Gibbs 
function:

\begin{table*}
    \centering
    \begin{tabular}{rrr}
        $U$          & $\dnor U =   T \dnor S - p \dnor V$ & $T = \left(\pfrac{U}{S}\right)_V$, $p = -\left(\pfrac{U}{V}\right)_S$ \\
        $H = U + PV$ & $\dnor H =   T \dnor S + p \dnor V$ & $T = \left(\pfrac{H}{S}\right)_V$, $V = \left(\pfrac{H}{p}\right)_S$ \\
        $F = U - TS$ & $\dnor F = - S \dnor T - p \dnor V$ & $S = -\left(\pfrac{F}{T}\right)_V$, $p = -\left(\pfrac{F}{V}\right)_T$ \\
        $G = H - TS$ & $\dnor G = - S \dnor T + V \dnor p$ & $S = -\left(\pfrac{G}{T}\right)_p$, $V = \left(\pfrac{G}{p}\right)_T$ \\
     \end{tabular}
\end{table*}

One convenience of these Thermodynamic potentials compared to the internal energy $U$ is that 
they are presented in more convenient variables. For example, for a system
that at a fixed volume and pressure during a process, we can know that its Gibbs 
function must remain the same during that process.

\subsection*{Maxwell's relationship}
Maxwell's relationship can be derived from the above  definition of the thermodynamic
potential function, and they are stated as below:
\begin{gather}
    \left(\pfrac{T}{V}\right)_S = - \left(\pfrac{p}{S}\right)_V \\
    \left(\pfrac{T}{p}\right)_S = \left(\pfrac{V}{S}\right)_p \\
    \left(\pfrac{S}{V}\right)_T = - \left(\pfrac{p}{T}\right)_V \\
    \left(\pfrac{S}{p}\right)_T = - \left(\pfrac{V}{T}\right)_V 
\end{gather}

\subsection*{Isothermal magnetization and adiabatic demagnetization}
To generalize the above treatment in general system, we can write:
\begin{equation}
    \dbar W = X dx
\end{equation}
where $X$ is some intensive generalized force and $x$ is some 
extensive generalized displacement.

Consider a system of magnetic moments arranged in a lattice. We 
assume paramagnetic system with no interaction between the magnetic moments. 
The first law of Thermodynamic for such system is 
\begin{equation}
    \dnor U = T \dnor S - m \dnor B
\end{equation}
We define the magnetic susceptibility as:
\begin{equation}
    \chi = \lim_{H\to0} \frac{M}{H} \approx \frac{\mu_0 M}{B}
\end{equation}
since $B = \mu_0(H+M)$ and $M \ll H$.
Curie's law states $\chi \propto 1/T$ and therefore
\begin{equation}
    \left(\pfrac{\chi}{T}\right)_B < 0
\end{equation}

Consider the Helmholtz function:
\begin{equation}
    \dnor F = - S \dnor T - m \dnor B
\end{equation}
which gives the Maxwell relation:
\begin{equation}
    \left(\pfrac{S}{B}\right)_T = \left(\pfrac{m}{T}\right)_B 
    \approx \frac{VB}{\mu_0} \left(\pfrac{\chi}{T}\right)_B
\end{equation}
The heat absorbed in an isothermal change of $B$ is:
\begin{equation}
    \Delta Q = T \left(\pfrac{S}{B}\right)_T \Delta B
    = \frac{TVB}{\mu_0} \left(\pfrac{\chi}{T}\right)_B \Delta B < 0
\end{equation}
So that an isothermal increase of $B$ will 
release heat to the environment.

The change in temperature in an adiabatic change of $B$ is 
\begin{equation}
    \left( \pfrac{T}{B} \right)_S = - \left( \pfrac{T}{S} \right)_B \left( \pfrac{S}{B} \right)_T
\end{equation}
using 
\begin{equation}
    C_B = T \left( \pfrac{S}{T} \right)_B    
\end{equation}
we have:
\begin{equation}
    \left( \pfrac{T}{B} \right)_S = - \frac{TVB}{\mu_0 C_B} \left(\pfrac{\chi}{T}\right)_B > 0
\end{equation}
So that in an adiabatic process, the temperature will decrease with the decrease of magnetization,
which is called \textbf{adiabatic demagnetization}

\section{Equipartition of energy}
To derive the equipartition theorem, we first consider a system
whose energy is given by a quadratic form:
\begin{equation}
    E = \alpha x^2
\end{equation}
where $\alpha$ is some positive constant and $x$ is a variable
that descript the microscopic configuration of the system. The 
probability of the system taking configuration $x$ is then 
given by the canonical distribution:
\begin{equation}
    P(x) = \frac{e^{-\beta \alpha x^2}}{\int_{-\infty}^{\infty} e^{-\beta \alpha x^2 dx}}
\end{equation}
The mean energy of the system is then:
\begin{align}
    \langle E \rangle &= \int_{-\infty}^{\infty} E P(x) dx \\
        & = \frac{\int_{-\infty}^{\infty} \alpha x^2 e^{-\beta \alpha x^2} dx}{\int_{-\infty}^{\infty} e^{-\beta \alpha x^2 dx}} \\
        & = \frac{1}{2} k_B T
\end{align}

For a system with multiple variables, we similarly have:
\begin{equation}
    E = \sum_{i=1}^n \alpha_i x_i^2
\end{equation}
The total energy is then:
\begin{align}
    \langle E \rangle 
        & = \frac{\int_{-\infty}^{\infty}\cdots\int_{-\infty}^{\infty} \sum_{i=1}^n \alpha_i x_i^2 e^{-\beta \sum_{j=1}^n \alpha_j x_j^2} dx_1 \cdots dx_n}{\int_{-\infty}^{\infty}\cdots\int_{-\infty}^{\infty} e^{-\beta \sum_{i=1} \alpha_i x_i^2} dx_1 \cdots dx_n} \\
        & = \sum_{i=1}^n \frac{\int_{-\infty}^{\infty}\cdots\int_{-\infty}^{\infty} \alpha_i x_i^2 e^{-\beta \sum_{j=1}^n \alpha_j x_j^2} dx_1 \cdots dx_n}{\int_{-\infty}^{\infty}\cdots\int_{-\infty}^{\infty} e^{-\beta \sum_{i=1} \alpha_i x_i^2} dx_1 \cdots dx_n} \\
        & = \sum_{i=1}^n \frac{\int_{-\infty}^{\infty} \alpha_i x_i^2 e^{-\beta \alpha_i x_i^2}  dx_i }{\int_{-\infty}^{\infty} e^{-\beta \alpha_i x_i^2}  dx_i } \\
        & = \sum_{i=1}^n  \frac{1}{2} k_B T = \frac{n}{2} k_B T
\end{align}
where $n$ the number of variable of the system ( microscope variable that determine the energy of the system), which we can call degree of freedom.

The formal equipartition theorem states: \emph{ If the energy of a classic system is the sum
of the $n$ quadratic variables and the system is in contact with a thermal reservior at temperature $T$, 
then its average energy is $n\times \frac{1}{2}k_B T$}

\subsection*{Application of equipartition theorem to heat capacitiy of crystals}
We consider each atom in the crystal are kept at their respective equilibrium positions
by a spring. Each atom is therefore described by 6 variables: their kinetic energy
is given by their velocity $\mathbf{v}$ and their potential energy by their 
position $\mathbf{r}$. Therefore, there are $6N$ degree of freedom in a solid 
with $N$ numbers of atoms. The total energy of the crystal at temperature $T$
is then:
\begin{equation}
    \langle E \rangle = 3N k_B T
\end{equation}
and the Molar heat capacitiy of a solid is then $3N_A k_B = 3R$, known as the Dulong-Petit rule.

\subsection*{Assumption and limitation of equipartition theorem}
The critical assumption we made in deriving the equipartition theorem is 
as follows:
\begin{enumerate}
    \item We have assumed that the system variable $x$ is continuous through the intergration $\int_{-\infty}^{\infty} E(x) P(x) dx$.
            However, for quantum system, the system are found to take distinct states with quantized energy levels. For example, at low temperature,
            thermal energy may not be enough to excite the system to the next energy level and the system will be in the ground state with $P = 1$.
            A classical system in this case assumes that there are always levels for system to distribute to even at low temperature and the above 
            integral is valid. 
    \item We assume that that the energy of the system can be written in a quadratic form. In most case this is valid, since the system will 
            minimize its energy in equilibrium and the energy can therefore be written as an expansion to second order: $ E = E_0 + \alpha (x - x_0)^2$ 
            around $x =x_0$. However, when temperature is high and $x$ start to deviate largely from $x_0$, 
            higher order terms become important and quadratic form is no longer valid.
\end{enumerate}
As a conclusion, we learned that the equipartition theorem is valid in a temperature range high enough so that states are almost continuous ($\Delta E \ll k_B T$ with
$\Delta E$ the energy difference between states) but 
low enough that the quadratic form of the energy is valid.

\section{The partition function}
We define the partition function as:
\begin{equation}
    Z = \sum_{\alpha} e^{-\beta E_{\alpha}}
\end{equation}
which allow us to derive all the important thermodynamic quantities. 

The internal energy is given by:
\begin{equation}
    U = \langle E \rangle = \frac{\sum_{i} E_i e^{-\beta E_i}}{\sum_{i} e^{-\beta E_i}} = -\frac{\dnor \ln Z}{\dnor\beta} = k_BT^2\frac{\dnor \ln Z}{\dnor T}
\end{equation}

The entropy is found by:
\begin{align}
    S = -k_B \sum_i P_i \ln P_i = k_B \sum_i P_i (\beta E_i + \ln Z) = k_B (\beta U + \ln Z)
\end{align}
or we can write:
\begin{equation}
    S = U/T + k_B \ln Z
\end{equation}

Helmholtz function can be written by $F = U - TS$, using the above result, we have:
\begin{gather}
    F = -k_B T \ln Z \\
    Z = e^{-\beta F}
\end{gather}

Other derived quantities can also be found:
\begin{gather}
    C_V = \left(\pfrac{U}{T}\right)_V = k_B T \left[ 2\left(\pfrac{\ln Z}{T}\right)_V + T \left( \frac{\partial^2\ln Z}{\partial T^2} \right)_V \right] \\
    p = - \left(\pfrac{F}{V}\right)_T = k_B T \left( \pfrac{\ln Z}{V} \right)_T \\
    H = U + pV =  k_B T \left[ \left( T\pfrac{\ln Z}{T}\right)_V + V \left( \pfrac{\ln Z}{V} \right)_T \right] \\
    G = F + pV =  k_B T \left[ -\ln Z + V \left( \pfrac{\ln Z}{V} \right)_T \right]
\end{gather}

It should be noted that the value of the partition function itself
is not uniquely defined, because the zero of the energy is arbitrary,
so that partitiona function can be defined up to an arbitrary multiplicative constant.
However, In terms of the thermodynamic quantities calculated in the above equations,
The result not on $Z$ but on $\ln Z$ and its derivative, so the 
those quantities are up to a additive constants or show no dependence on the 
arbitrarness of the partition function.

\section{Chemical potential and Grand potential}
We consider adding particles to a system, then the internal energy of the system will
increase by an amount, which we denote \textbf{chemical potential}. For a large system
with $\mu$ not changing significantly by adding or removing a particle, we have
\begin{equation}
    \dnor U = T \dnor S - p \dnor V + \mu \dnor N \label{du_dmu}
\end{equation}
with $N$ the particle number and $\mu$ can be written:
\begin{equation}
    \mu = \left( \pfrac{U}{N} \right)_{S,V}
\end{equation}
In terms of other constrains, we have:
\begin{gather}
    \dnor F = -p \dnor V - S \dnor T + \mu \dnor N \\
    \dnor G = V \dnor p - S \dnor T + \mu \dnor N
\end{gather}
and we have the expression for chemical potential as:
\begin{equation}
    \mu = \left( \pfrac{F}{N} \right)_{T,V} = \left( \pfrac{G}{N} \right)_{T,p}
\end{equation}

For an isolated system, the entrope will increase as system go to equilibrium. 
We write:
\begin{align}
    \dnor S &= \left( \pfrac{S}{U} \right)_{N,V} \dnor U + 
              \left( \pfrac{S}{V} \right)_{N,U} \dnor V + 
              \left( \pfrac{S}{N} \right)_{U,V} \dnor N \\
            &= \frac{\dnor U}{T} + \frac{p \dnor V}{T} - \frac{\mu \dnor N}{T}
\end{align}
where the second equality follow from Eq.\ref{du_dmu}. 
Therefore, we identify:
\begin{equation}
    \left( \pfrac{S}{U} \right)_{N,V} = \frac{1}{T}; \ \ \
    \left( \pfrac{S}{V} \right)_{N,U} = \frac{p}{T}; \ \ \
    \left( \pfrac{S}{N} \right)_{U,V} =-\frac{\mu}{T}
\end{equation}

We consider two system connected to each other and isolated from 
from the environment, If heat is allowed to follow, we have:
\begin{align}
    \dnor S &= \left( \pfrac{S_1}{U_1} \right)_{N,V} \dnor U_1 + \left( \pfrac{S_2}{U_2} \right)_{N,V} \dnor U_2 \\
        &= \left( \frac{1}{T_1} - \frac{1}{T_2} \right) \dnor U_1 \ge 0
\end{align}
Therefore, the equilibrium can be found at $T_1 = T_2$.

Similarly, if the system are allowed to exchange particle, we have:
\begin{align}
    \dnor S = \left( \frac{\mu_1}{T_1} - \frac{\mu_2}{T_2} \right) \dnor N_1 \ge 0
\end{align}
the equilibrium can be found at $\mu_1 = \mu_2$, if the two subsystem have 
already the same temperature.

\subsection*{Grand partition function}
For a grand canonical ensemble, The probability that a system
will be in a state with energy $E_i$ and particle number $N_i$ are 
given by
\begin{equation}
    P_i = \frac{e^{\beta(\mu N_i - E_i)}}{\mathcal{Z}}
\end{equation}
and the grand partition function $\mathcal{Z}$ is given by:
\begin{equation}
    \mathcal{Z} = \sum_i e^{\beta(\mu N_i - E_i)}
\end{equation}

We can find the thermodynamic quantities using $\mathcal{Z}$ in 
a similar way as with $Z$, with the result:
\begin{gather}
   \langle N \rangle = \sum_i N_i P_i = k_B T \left( \pfrac{\ln \mathcal{Z}}{\mu} \right)_T \\
    U = - \left( \pfrac{\ln \mathcal{Z}}{\beta} \right)_{\mu} + \mu N \\
    S = -k_B \sum_i P_i \ln P_i = \frac{U - \mu N + k_B T\ln \mathcal{Z}}{T} \label{grand_entropy}
\end{gather}

We further define the grand potential:
\begin{equation}
    \Phi_G = -k_B T \ln \mathcal{Z}
\end{equation}
which is a function of state. We have, using Eq.\ref{grand_entropy}:
\begin{gather}
    \Phi_G = -k_B T \ln \mathcal{Z} = U - TS - \mu N = F - \mu N \\
    \dnor \Phi_G = \dnor F - \mu \dnor N - N \dnor \mu
\end{gather}

\subsection*{Different types of particles}
If there are different types of particle, we can write:
\begin{gather}
    \dnor U = T \dnor S - p \dnor V + \sum_i \mu_i \dnor N_i \\
    \dnor F = -p \dnor V - S \dnor T + \sum_i \mu_i \dnor N_i \\
    \dnor G = V \dnor p - S \dnor T + \sum_i \mu_i \dnor N_i 
\end{gather}

\end{document}
