\documentclass{article}
\usepackage{amssymb, amsmath, amsthm}
\usepackage[margin=1in]{geometry}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{hyperref} % \url \href

\newcommand{\pfrac}[2]{\frac{\partial #1}{\partial #2}}
% \renewcommand{\H}{\mathcal{H}}
\newcommand{\bbz}{\mathbb{Z}}
\newcommand{\bbr}{\mathbb{R}}
\newcommand{\calf}{\mathcal{F}}

\begin{document}

\title{Summary for Steerable CNN}
\author{Wenhao Zhang\\National Institute of Materials Science}
\date{\today}
\maketitle

\section{Introduction}
We describe the steerable CNNs that is purposed by Cohen and Welling 2016\cite{CW2016} and Weiler et al. 2018\cite{W2018_3D, W2018_Learning}. 
Basically, the so called steerable CNN is an extension of the standard CNN that are designed to contain extra (rotational) transformation properties through the filters.
Recall that the group equivariant CNNs contain those transformation properties by defining the feature map domain to be that of the group action. 
For steerable CNNs, the feature map defined is the same as the standard translation CNNs but now the channels are vectors must 
transform with required transformation properties. 
In contrast, the channels in the standard CNNs or group equivariant CNNs are independent.

A feature map $\calf$ is called steerable with respect to group $G$ of transformation if it has the same transformation properties of the input
(we know how to steer the output feature map given a transformed input).
One specifically nice property about steerable CNNs is that, since the channels have certain transformation properties, it is very natural 
to consider the channels as vectors to be transformed by the group action. This properties is suitable for application in physics. 
However, one of the draw back of the steerable CNNs as purposed is that it applies to data on grids, or volumetric data.

\section{Formulation on images}
\subsection*{Equivariance}
We define an 2D-image: $f_l\colon \bbz^2 \to \bbr^{N_l}$ with $N_l$ channels at layer $l$. For $x\in \bbz^2$, we call $f_l(x)$ a \emph{fiber}
of the image, which we consider as a vector in $F_x^l$ vector space. 
The action of group element $g=tr \in G$ on the input image $f$ is written:
\begin{equation}
    [\pi(g) f](x) = f(g^{-1}x)
    \label{E:representation_on_input}
\end{equation}
the vector space $\calf$ of 2D-image with the linear action $\pi(g)$ form a representation of $G$

We define a \emph{filter} as a linear map $\Psi\colon \calf \to \bbr^{N_{l+1}}$.
These filters can be parameterized just like that in the standard CNN as a tensor with dimension $N_l\times N_{l+1}\times s\times s$, where $s$ are the 
patch size (for example, $2\times 2$) that the filter operate on, $N_l$ is the input channel and $N_{l+1}$ is the length of the output channel. 
The filters take a patch of input of the image $f_l$ and all its channels ($N\times s^2$) and output a single vector $f_{l+1}(x) \in F^{l+1}_x$ (fiber vector space).
They are in vector space of the representation $\pi$ and $\rho$. 
For a subgroup $H\subset G$, we require the filter $\Psi$ to be \emph{H-equivariant}:
\begin{equation}
    \label{E:H-equivariant}
    \rho(h)[\Psi \circ f] = \Psi \circ \pi(h)f \qquad h \in H
\end{equation}
recall that $\rho$ gives a representation of $H$ that act on the vector space of fiber $F_x$.
This condition means that, $f_{l+1}(x)$ obtained by applying filter after the transformation of $h$ (by $\pi(h)$) on the image is equivalent
to first applying the filter, than apply action of $h$ (by $\rho(h)$) in the vector space of the fiber $F_{x}^{l+1}$. 
Therefore, filter operation is a homomorphism between the two representation for group $H$. 
The vector space of all such homomorphism can be denoted as $\text{Hom}_H(\pi, \rho)$. 

We apply the filter on feature map by \emph{convoluting it with a translated 
feature map} (we fix the filter at origin and move the feature map)
\begin{equation}
    f_{l+1}(x) = [\Psi \circ f_l](x) = \Psi \star ( \pi(x)^{-1} f_l )
\end{equation}
in $\pi(x)$, $x$ denote a translation, instead of a coordinate. 
Thene, for a general operation $g = tr$ with $t\in T$, $r \in H$, we have the transformation 
properties:
\begin{align*}
    [\Psi \circ (\pi(tr)f_l)](x) 
        &= \Psi \star \pi(x^{-1})\pi(tr) f_l \\
        &= \Psi \star \pi(x^{-1}tr) f_l \\
        &= \Psi \star \pi(rr^{-1}x^{-1}tr) f_l \\
        &= \Psi \star \pi(r) \pi(r^{-1}x^{-1}tr) f_l \\
        &= \rho(r) \Psi \star \pi\left(\left((tr)^{-1}x\right)^{-1}\right) f_l \\
        &= \rho(r) [ \Psi \star  f_l ]  ((tr)^{-1}x)\\
        &= \rho(r) (\pi(tr) f_{l+1}) (x) 
\end{align*}
$[\Psi \circ (\pi(tr)f_l)]$ means we transform the input feature map $f_l$ by the action of $tr$, then applying the filter. The right hand side
$\rho(r) [ \Psi \star  f_l ]  ((tr)^{-1}x)$ means we 
1) apply the filter, 
2) transform the feature map using relation $x\to(tr)^{-1}x$ and 
3) apply the transformation $\rho(r)$ on the output fibers.
If we define transformation $\Pi$ (induced transformation) on the output feature map:
\begin{equation}
    [\Pi(tr) f ](x)= \rho(r) (\pi(tr) f) (x) \label{induced_transformation}
\end{equation}
Then we obtain the equivariance:
\begin{equation}
    \tag{Equivariance}
    \Psi \circ \pi(g) f = \Pi(g) [\Psi \circ f]
\end{equation}
we take care to distinguish the effect of $\pi$ and $\Pi$. $\pi$ operation on the feature map as according to 
\[[\pi(g) f](x) = f(g^{-1}x)\]
which trans-rotate the feature map, 
while $\Pi$ trans-rotate the feature map, as well as rotating the fibers.

\subsection*{Choosing the filters}
Recall from the previous section that 
applying the filters on the feature map generate a vector (fiber) in the vector space. 
The filters take a patch of input of the image with all its channels $N_l\times s^2$ and output a single vector $N_{l+1}$, in respective vector space of the 
representation $\pi$ and $\rho$, and the filter operation belong to a homomorphism $\text{Hom}_H(\pi, \rho)$. 

For input image as well as its channels, the transformation $\pi(g)$ is known. For the feature maps in the later layers, 
their transformation is also known and is given by the induced representation $\Pi(g)$ from equation \eqref{induced_transformation}
if the representation of $\rho$ is known. 

\subsubsection*{Choosing representation $\rho$}
From the representation theory, we know that for any representation, it can be 
block diagonalized by its irreducible representations
Irreducible representations of a group $H$ are generally known and tabulated, for example, in character tables. 
Therefore, to specify the representation of $\rho$, we 
only need to choice the the irreducible representations and their multiplicity, as well as a suitable matrix that transform the base.
(hese can be considered as hyperparameters of the network).

\subsubsection*{Choosing the filter}
After choosing $\rho$, we find the mapping $\Phi$ between the representation $\pi$ and $\rho$ in terms of a set of 
basis mapping. The filter $\Phi$ is finally expressed as a linear combination of the basis mappings. This is detailed in 
Cohen and Welling 2016, section 2.7

After knowing the mapping $\Phi$ and the representation $\pi$ and $\rho$, the representation of the output feature map is given by 
the induced representation $\Pi$ equation \eqref{induced_transformation}. Again, define $\rho$ and find the mapping, we can 
contain the process until we arrive at the desired output.


\section{Formulation for 3-dimensional space}
In Weiler et al. 2018, a steerable CNN for SE(3) is purposed. 
The starting point of the formulation is the induced representation equation \eqref{induced_transformation}, which gives the transformation 
properties for a group action $g$ on a feature map $f$:
\begin{equation}
    [\Pi(tr) f ](x)= \rho(r) (\pi(tr) f) (x)
\end{equation}

Writing for a general kernel $\kappa\colon \bbr^3 \times \bbr^3 \to \bbr^{N_{l+1}\times N_{l}}$, the later part correspond to weight matrix 
between $N_l$ input feature channels and $N_{l+1}$ output feature channels. 
we denote the mapping of feature $\calf_n \to \calf_{n+1}$ as 
\begin{equation}
    f_{l+1}(x) = [\kappa \circ f_l](x) = \int_{\bbr^3} \kappa(x,y) f_l(y) dy \label{E:kernel_operation}
\end{equation}
This is a equivariant mapping to SE(3) if:
\begin{equation}
    \kappa \circ [\Pi_1 (g)f](x) = \Pi_2 (g) [\kappa \circ f](x) \label{E:kernel}
\end{equation} 
The left hand side of the equation can be evaulated as:
\begin{align*}
    [ \kappa \circ \Pi_1 (tr)f ] (x) &= [\kappa \circ \rho(r) (\pi(tr) f) ](x) \\
    &= \int_{\bbr^3} \kappa(x,y) \rho_1(r) \pi(tr) f(y) dy \\
    &= \int_{\bbr^3} \kappa(x,y) \rho_1(r) f((tr)^{-1}y) dy \\
    &= \int_{\bbr^3} \kappa(x,(tr)y) \rho_1(r) f(y) dy 
\end{align*}
On the right, we have:
\begin{align*}
    \Pi_2 (g) [\kappa \circ f](x) &= \Pi_2 (g) \int_{\bbr^3} \kappa(x,y) f(y) dy \\
    &= \rho_2(r) \int_{\bbr^3} \kappa((tr)^{-1}x,y) f(y) dy
\end{align*}
Equating the two parts and using $g= tr$, we therefore require:
\begin{align}
    \kappa(x,gy) \rho_1(r) &= \rho_2(r) \kappa(g^{-1}x,y) \notag \\
    \kappa(gx,gy) \rho_1(r) &= \rho_2(r) \kappa(x,y) \notag \\
    \kappa(gx,gy) &= \rho_2(r) \kappa(x,y) \rho_1(r) ^{-1} \label{E:kernel_require}
\end{align}
Therefore, to satisfy the equivariance equation \eqref{E:kernel}, the kernel need to behave as above 
with respect to $\rho_1$ and $\rho_2$. 

For a kernel in this form, it is translation invariant: if $g$ is a pure translation, 
then $\kappa(gx,gy) =  \kappa(x,y)$. Therefore, taking $g = x^{-1}$, we find:
\begin{equation}
    \kappa(0,y-x) = \kappa(x,y)
\end{equation}
i.e., $\kappa$ only depend on the relative distance between its inputs and equation \eqref{E:kernel_operation}
reduce to a standard correlation (taking $g=y^{-1}$ gives convolution):
\begin{equation}
    f_{l+1}(x) = [\kappa \circ f](x) = \int_{\bbr^3} \kappa(y-x) f(y) dy
\end{equation}
where the kernel $\kappa$ is a function $\kappa \colon \bbr^3 \to \bbr^{N_{l+1}\times N_{l}}$

\subsection*{Finding the kernel $\kappa$}
To find the form of the kernel, it need to satisfy equation \ref{E:kernel_require}. For $r \in \text{SO(3)}$, 
it is natural that the representation $\rho$ is given by direct sum of the irreducible representation of rotation,
given by block diagonal form consisting the wigner matrix (with a suitable change of basis). 
For rotation order $j$ and $l$, equation \ref{E:kernel_require}
can be written as:
\begin{equation}
    \kappa^{jl}(rx) = D^{j}(r) \kappa^{jl}(x) D^l(r)^{-1}
\end{equation}
We can find the kernel can be written as a linear combination of basis kernel function that satisfy this requirement. 
For detail, we can refer to section 4.2 in Weiler et al. 2018.

\section*{Rotation equivariant}
In Weiler et al. 2018, rotational equivariant version of the steerable CNN is applied to image data and achieve good accuracy. 
This is named steerable CNN but in concept, this work is closer to the group equivariant CNNs rather than the above mention steerable CNNs. 
The key point in their work is that, just like in standard CNN where image is convoluted with weight sharing translated filters, 
they convolute the image with rotated version of the filter with weight sharing. 
This is achieved by writing the filter as a combination of function:
\begin{align*}
    \Psi(x) &= \sum_j \sum_k w_{jk}\psi_{jk}(x) \\
            &= \sum_j \sum_k w_{jk} R_j(r) e^{ik\phi}
\end{align*}
$r$ and $\phi$ are the polar coordinates of a pixel and $R_j$ a radial basis function. In this form, a rotation 
of the filter is given by simply $\rho_{\theta}e^{ikx} = e^{ik(x-\theta)}$
We convolute the image with the image $I$ with $N$ rotated filter $\rho_{\theta}\Psi(x)$ ($\theta = 2\pi / N$):
\begin{align*}
    y_{c'}(x,\theta) &= \sum_c [ I_c \circ \rho_{\theta}\Psi ] (x) \\
        &= \sum_c \sum_j \sum_k w_{c'cjk} e^{-ik\theta} [I_c \circ \psi_{jk}](x)
\end{align*}
We can recognize that the network operate 
very similar to spherical CNN (Cohen et al. 2018) with decretized rotations. The channels are independent and the notion of fiber 
are not presented.

%Cohen and Welling 2016, Weiler et al. 2018a and 2018b
\begin{thebibliography}{9}
    \bibitem{CW2016} 
    T. S. Cohen and M. Welling, “Steerable CNNs,” arXiv:1612.08498 [cs, stat], Dec. 2016, Accessed: Feb. 04, 2022. [Online]. Available: http://arxiv.org/abs/1612.08498
    \bibitem{W2018_3D}
    M. Weiler, M. Geiger, M. Welling, W. Boomsma, and T. Cohen, “3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data,” arXiv:1807.02547 [cs, stat], Oct. 2018, Accessed: Jan. 31, 2022. [Online]. Available: http://arxiv.org/abs/1807.02547
    \bibitem{W2018_Learning}
    M. Weiler, F. A. Hamprecht, and M. Storath, “Learning Steerable Filters for Rotation Equivariant CNNs,” in 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, Jun. 2018, pp. 849–858. doi: 10.1109/CVPR.2018.00095.
\end{thebibliography}

\end{document}